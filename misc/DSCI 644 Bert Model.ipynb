{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8400574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from textblob import TextBlob\n",
    "\n",
    "#model-building\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "619739f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a346d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_commits.csv')\n",
    "commits = df['Commit message']\n",
    "ref_type = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35173e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase, strip, remove punctuation\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text= text.strip()  \n",
    "    text= re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e53ad60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword removal\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b24b6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final preprocessing\n",
    "def finalpreprocess(string):\n",
    "    return stopword(preprocess(string))\n",
    "commits_pr = commits.apply(lambda x: finalpreprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5537d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_pr = commits_pr.apply(lambda x: x.split()[:32])\n",
    "commits_pr = pd.Series([' '.join(map(str, l)) for l in commits_pr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a269c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          extract method\n",
       "1       minor tweaks following review extraction metho...\n",
       "2       extract stuff method git p depot paths coremed...\n",
       "3                          extract methods doiserviceimpl\n",
       "4       refactoring getmenuspace navigation extract is...\n",
       "                              ...                        \n",
       "4999           rename getprotocol getmechanism testclient\n",
       "5000    rename mapping methods mapfrom mapto signed lu...\n",
       "5001    renaming refactor deserialization related code...\n",
       "5002    renamed usage description match name used comm...\n",
       "5003    renamed isoccupied point point hasroaduseron p...\n",
       "Length: 5004, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "028a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_commits_preproc = pd.concat([commits_pr, ref_type], axis=1, join='inner')\n",
    "labeled_commits_preproc.rename(columns={0: 'Commit message'}, inplace=True)\n",
    "labeled_commits_preproc.head()\n",
    "df = labeled_commits_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b1f93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict = {'extract':0,'inline':1, 'move':2, 'pull up':3, 'push down':4, 'rename':5}\n",
    "df['Class_Num'] = df.Class.map(encoded_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e96b6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b064e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf08aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Commit message']\n",
    "y = df['Class_Num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ccf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d5b3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ba4089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(\n",
    "    text=X_train.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=32,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "X_test = tokenizer(\n",
    "    text=X_test.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=32,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3c9b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(4003, 32), dtype=int32, numpy=\n",
       "array([[  101,  4275, 15430, ..., 14467, 12272,   102],\n",
       "       [  101,  3137,  8313, ...,     0,     0,     0],\n",
       "       [  101,   187,  2087, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 10625,  1231, ...,  1116,  1112,   102],\n",
       "       [  101,   191,  2944, ...,     0,     0,     0],\n",
       "       [  101,  8130,  4684, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(4003, 32), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "322b99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = X_train['input_ids']\n",
    "attention_mask = X_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0933c83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1001, 32), dtype=int32, numpy=\n",
       "array([[  101,  1231,  8057, ...,     0,     0,     0],\n",
       "       [  101,   179, 15677, ...,     0,     0,     0],\n",
       "       [  101,  1815,  2373, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  4275,  9726, ...,  1179, 25021,   102],\n",
       "       [  101,  1231, 16124, ...,     0,     0,     0],\n",
       "       [  101,  1231,  8057, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44ec6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b25049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(6,activation = 'sigmoid')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "769a117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=5e-5,\n",
    "    epsilon=1e-08,\n",
    "    clipnorm=1.0,\n",
    "    weight_decay=0.01)\n",
    "# Set loss and metrics\n",
    "loss = CategoricalCrossentropy(from_logits = False)\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9352e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "167/167 [==============================] - 513s 3s/step - loss: 1.4165 - balanced_accuracy: 0.4179 - val_loss: 1.1644 - val_balanced_accuracy: 0.5395\n",
      "Epoch 2/5\n",
      "167/167 [==============================] - 494s 3s/step - loss: 1.1142 - balanced_accuracy: 0.5618 - val_loss: 1.1384 - val_balanced_accuracy: 0.5774\n",
      "Epoch 3/5\n",
      "167/167 [==============================] - 493s 3s/step - loss: 0.9816 - balanced_accuracy: 0.6238 - val_loss: 1.1505 - val_balanced_accuracy: 0.5674\n",
      "Epoch 4/5\n",
      "167/167 [==============================] - 498s 3s/step - loss: 0.8598 - balanced_accuracy: 0.6812 - val_loss: 1.0935 - val_balanced_accuracy: 0.5784\n",
      "Epoch 5/5\n",
      "167/167 [==============================] - 494s 3s/step - loss: 0.6938 - balanced_accuracy: 0.7587 - val_loss: 1.1416 - val_balanced_accuracy: 0.5784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_history = model.fit(\n",
    "    x ={'input_ids':X_train['input_ids'],'attention_mask':X_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':X_test['input_ids'],'attention_mask':X_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=5,\n",
    "    batch_size=24\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92157151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 22s 638ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5435681 , 0.83902055, 0.8576314 , 0.7128423 , 0.65960366,\n",
       "       0.22812688], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_raw = model.predict({'input_ids':X_test['input_ids'],'attention_mask':X_test['attention_mask']})\n",
    "predicted_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d0673ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(y_test, columns = [0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b80bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 0, 5, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_test['Class'] = np.where(df_test[0]==1.0, 0,\n",
    "                           np.where(df_test[1]==1.0, 1,\n",
    "                                   np.where(df_test[2]==1.0, 2,\n",
    "                                           np.where(df_test[3]==1.0, 3,\n",
    "                                                    np.where(df_test[4]==1.0, 4,5)))))\n",
    "\n",
    "df_test_class = df_test['Class']\n",
    "df_test_class = df_test_class.to_numpy()\n",
    "df_test_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "141182c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
    "y_true = df_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "228b34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69       167\n",
      "           1       0.42      0.50      0.45       167\n",
      "           2       0.49      0.70      0.57       166\n",
      "           3       0.49      0.42      0.45       167\n",
      "           4       0.45      0.37      0.40       167\n",
      "           5       0.94      0.88      0.91       167\n",
      "\n",
      "    accuracy                           0.58      1001\n",
      "   macro avg       0.60      0.58      0.58      1001\n",
      "weighted avg       0.60      0.58      0.58      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/12/multiclass-classification-using-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e635283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>127</td>\n",
       "      <td>199</td>\n",
       "      <td>238</td>\n",
       "      <td>144</td>\n",
       "      <td>137</td>\n",
       "      <td>156</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   All\n",
       "Actual                                       \n",
       "0          102   23   16    9   17    0   167\n",
       "1            9   83   26   25   21    3   167\n",
       "2            7   11  116   13   14    5   166\n",
       "3            5   29   39   70   23    1   167\n",
       "4            3   49   27   27   61    0   167\n",
       "5            1    4   14    0    1  147   167\n",
       "All        127  199  238  144  137  156  1001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_predicted)\n",
    "pd.crosstab(y_true, y_predicted, rownames = ['Actual'], colnames =['Predicted'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7189173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
