{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8400574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#model-building\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bbc856",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a346d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_commits.csv')\n",
    "commits = df['Commit message']\n",
    "ref_type = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93452803",
   "metadata": {},
   "source": [
    "## Splitting into training and test data to evaluate each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e4f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = commits\n",
    "y = ref_type\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb21585",
   "metadata": {},
   "source": [
    "## Defining methods for lower-casing and stripping noise, punctuation\n",
    "To be used for all datasets/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35173e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase, strip, remove punctuation\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.sub(r'https*\\S+', ' ', text) # remove links\n",
    "    text = re.sub(r'http*\\S+', ' ', text)\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28085f",
   "metadata": {},
   "source": [
    "## Defining methods for further preprocessing: stop-word removal and lemmatization\n",
    "To be used with datasets/models for replication of AlOmar et al.'s models and with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53ad60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword removal\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47c519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "wl = WordNetLemmatizer()\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f2fdc",
   "metadata": {},
   "source": [
    "## Preprocessing dataset for replication and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24b6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final preprocessing\n",
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "rep_train = X_train.apply(lambda x: finalpreprocess(x))\n",
    "rep_test = X_test.apply(lambda x: finalpreprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54277f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commit message</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>fix bug rulesets disable properly also add com...</td>\n",
       "      <td>inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>minor improvement probe</td>\n",
       "      <td>push down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>rf remove unused formal parameter</td>\n",
       "      <td>inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>sgf provide support sdg xml namespace load pre...</td>\n",
       "      <td>pull up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>remove usage deprecate method collection key</td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Commit message      Class\n",
       "1855  fix bug rulesets disable properly also add com...     inline\n",
       "3788                            minor improvement probe  push down\n",
       "2336                  rf remove unused formal parameter     inline\n",
       "2819  sgf provide support sdg xml namespace load pre...    pull up\n",
       "835        remove usage deprecate method collection key       move"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replic_preproc_train = pd.concat([rep_train, y_train], axis=1, join='inner')\n",
    "replic_preproc_test = pd.concat([rep_test, y_test], axis=1, join='inner')\n",
    "replic_preproc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1087a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replic_preproc_train.to_csv('replication_preproc_train.csv', index=False)\n",
    "# replic_preproc_test.to_csv('replication_preproc_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a3346",
   "metadata": {},
   "source": [
    "## Preprocessing dataset for BERT and fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9894ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_ft_finalpreprocess(string):\n",
    "    return preprocess(string)\n",
    "\n",
    "bert_ft_train = X_train.apply(lambda x: bert_ft_finalpreprocess(x))\n",
    "bert_ft_test = X_test.apply(lambda x: bert_ft_finalpreprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e6aea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commit message</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>fixed bug where rulesets were not being disabl...</td>\n",
       "      <td>inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>a few minor improvements to probes</td>\n",
       "      <td>push down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>rf remove unused formal parameter</td>\n",
       "      <td>inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>sgf provide support in the sdg xml namespace t...</td>\n",
       "      <td>pull up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>removed usage of the deprecated method collect...</td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Commit message      Class\n",
       "1855  fixed bug where rulesets were not being disabl...     inline\n",
       "3788                 a few minor improvements to probes  push down\n",
       "2336                  rf remove unused formal parameter     inline\n",
       "2819  sgf provide support in the sdg xml namespace t...    pull up\n",
       "835   removed usage of the deprecated method collect...       move"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_ft_preproc_train = pd.concat([bert_ft_train, y_train], axis=1, join='inner')\n",
    "bert_ft_preproc_test = pd.concat([bert_ft_test, y_test], axis=1, join='inner')\n",
    "bert_ft_preproc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f79702c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_ft_preproc_train.to_csv('bert_ft_preproc_train.csv',index=False)\n",
    "# bert_ft_preproc_test.to_csv('bert_ft_preproc_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a48fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
