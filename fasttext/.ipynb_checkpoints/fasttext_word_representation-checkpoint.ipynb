{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd03aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3a844",
   "metadata": {},
   "source": [
    "## Creating corpus to be used for pre-training FastText model\n",
    "Corpus contains 100,000 randomly sampled messages from the GitHub Commit Messages Dataset: https://www.kaggle.com/datasets/dhruvildave/github-commit-messages-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be779af",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('commits_dataset.csv')\n",
    "messages['message'] = messages['message'].astype(pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d87726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DOC: add example for plotting asymmetrical err...\n",
       "1             Add keyword sort to pivot_table (#40954)\n",
       "2     ENH: `Styler.highlight_quantile` method (#40926)\n",
       "3    ENH: add `decimal` and `thousands` args to `St...\n",
       "4    [ArrowStringArray] Use utf8_upper and utf8_low...\n",
       "Name: message, dtype: string"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = messages['message'].dropna()\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70080e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 4335970 entries, 0 to 4336298\n",
      "Series name: message\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "4335970 non-null  string\n",
      "dtypes: string(1)\n",
      "memory usage: 66.2 MB\n"
     ]
    }
   ],
   "source": [
    "messages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa3587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_test = pd.DataFrame(messages.sample(n=100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc325957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639ad3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_test['message'] = message_test['message'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5826c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "message_test['message'] = message_test['message'].apply(lambda x: simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820f792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 1566412 to 402158\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   message  100000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "message_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ec9cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('commit_corpus_100k.txt', 'w', encoding='UTF-8') as f:\n",
    "    for message in message_test['message']:\n",
    "        for s in message:\n",
    "            f.write(s + ' ')\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b31a31",
   "metadata": {},
   "source": [
    "## Creating pretrained embeddings with corpus of 100,000 pre-processed commit messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dd5306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  28309\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   94936 lr:  0.000000 avg.loss:  1.713304 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_unsupervised('commit_corpus_100k.txt',\n",
    "                                    'cbow',\n",
    "                                    dim=100,\n",
    "                                    wordNgrams=2,\n",
    "                                    thread = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae922e",
   "metadata": {},
   "source": [
    "## Converting model to vec file to be used in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a2d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('fasttext_embeds.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b9851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#convert bin to vec\n",
    "from fasttext import load_model\n",
    "\n",
    "# original BIN model loading\n",
    "f = load_model('fasttext_embeds.bin')\n",
    "lines=[]\n",
    "\n",
    "# get all words from model\n",
    "words = f.get_words()\n",
    "\n",
    "with open('fasttext_embeds.vec','w') as file_out:\n",
    "    \n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = f.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ca3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
