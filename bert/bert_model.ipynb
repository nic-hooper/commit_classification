{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d4844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,TFBertModel\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654dbb2",
   "metadata": {},
   "source": [
    "## Importing and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1416ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('bert_ft_preproc_train.csv')\n",
    "train_data.rename(columns={'Class':'type','Commit message':'text'}, inplace=True)\n",
    "train_data['text'] = train_data['text'].astype(pd.StringDtype())\n",
    "test_data = pd.read_csv('bert_ft_preproc_test.csv')\n",
    "test_data.rename(columns={'Class':'type','Commit message':'text'},inplace=True)\n",
    "test_data['text'] = test_data['text'].astype(pd.StringDtype())\n",
    "label_dict = {'extract':0,'inline':1, 'move':2, 'pull up':3, 'push down':4, 'rename':5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d434dd",
   "metadata": {},
   "source": [
    "## Converting labels to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155370dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'] = test_data.type.map(label_dict)\n",
    "train_data['label'] = train_data.type.map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b819cc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed bug where rulesets were not being disabl...</td>\n",
       "      <td>inline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a few minor improvements to probes</td>\n",
       "      <td>push down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf remove unused formal parameter</td>\n",
       "      <td>inline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sgf provide support in the sdg xml namespace t...</td>\n",
       "      <td>pull up</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>removed usage of the deprecated method collect...</td>\n",
       "      <td>move</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>completely overhaul and clean up basic archite...</td>\n",
       "      <td>push down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>rename method to match any java style guide</td>\n",
       "      <td>rename</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>wagon refactor ssh tests in prep to get some s...</td>\n",
       "      <td>push down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>vishal refactoring remove redundant db calls t...</td>\n",
       "      <td>inline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>handling push link contract results per messag...</td>\n",
       "      <td>push down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4003 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       type  label\n",
       "0     fixed bug where rulesets were not being disabl...     inline      1\n",
       "1                    a few minor improvements to probes  push down      4\n",
       "2                     rf remove unused formal parameter     inline      1\n",
       "3     sgf provide support in the sdg xml namespace t...    pull up      3\n",
       "4     removed usage of the deprecated method collect...       move      2\n",
       "...                                                 ...        ...    ...\n",
       "3998  completely overhaul and clean up basic archite...  push down      4\n",
       "3999        rename method to match any java style guide     rename      5\n",
       "4000  wagon refactor ssh tests in prep to get some s...  push down      4\n",
       "4001  vishal refactoring remove redundant db calls t...     inline      1\n",
       "4002  handling push link contract results per messag...  push down      4\n",
       "\n",
       "[4003 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35b900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train_data['label'])\n",
    "y_test = to_categorical(test_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49abc55",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7987ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a87cd9",
   "metadata": {},
   "source": [
    "## Preprocess the data into a format BERT can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b80d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text=train_data['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=200,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "x_test = tokenizer(\n",
    "    text=test_data['text'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=200,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c90e6",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c54ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(6,activation = 'sigmoid')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451335e",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e4ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
    "    epsilon=1e-08,\n",
    "    clipnorm=1.0)\n",
    "# Set loss and metrics\n",
    "loss =CategoricalCrossentropy()\n",
    "metric = CategoricalAccuracy('balanced_accuracy'),\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e16bf3",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f049d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "126/126 [==============================] - 2254s 18s/step - loss: 1.3971 - balanced_accuracy: 0.4272 - val_loss: 1.1197 - val_balanced_accuracy: 0.5764\n",
      "Epoch 2/5\n",
      "126/126 [==============================] - 2232s 18s/step - loss: 1.0506 - balanced_accuracy: 0.6008 - val_loss: 1.0535 - val_balanced_accuracy: 0.5984\n",
      "Epoch 3/5\n",
      "126/126 [==============================] - 2229s 18s/step - loss: 0.9024 - balanced_accuracy: 0.6615 - val_loss: 0.9910 - val_balanced_accuracy: 0.6184\n",
      "Epoch 4/5\n",
      "126/126 [==============================] - 2228s 18s/step - loss: 0.7795 - balanced_accuracy: 0.7170 - val_loss: 1.0985 - val_balanced_accuracy: 0.5934\n",
      "Epoch 5/5\n",
      "126/126 [==============================] - 2226s 18s/step - loss: 0.6222 - balanced_accuracy: 0.7772 - val_loss: 1.1867 - val_balanced_accuracy: 0.5914\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_data = (\n",
    "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
    "    ),\n",
    "  epochs=5,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815811b",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d40eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 167s 5s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3743481 , 0.8243222 , 0.5668551 , 0.9176102 , 0.7274624 ,\n",
       "       0.24616697], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
    "predicted_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada46fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
    "y_true = test_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d68937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       4\n",
       "2       4\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "996     3\n",
       "997     0\n",
       "998     0\n",
       "999     5\n",
       "1000    3\n",
       "Name: label, Length: 1001, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f23492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68       167\n",
      "           1       0.46      0.26      0.34       167\n",
      "           2       0.70      0.75      0.72       166\n",
      "           3       0.38      0.53      0.44       167\n",
      "           4       0.38      0.47      0.42       167\n",
      "           5       0.96      0.95      0.95       167\n",
      "\n",
      "    accuracy                           0.59      1001\n",
      "   macro avg       0.61      0.59      0.59      1001\n",
      "weighted avg       0.61      0.59      0.59      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a5a1a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>124</td>\n",
       "      <td>95</td>\n",
       "      <td>177</td>\n",
       "      <td>234</td>\n",
       "      <td>206</td>\n",
       "      <td>165</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2    3    4    5   All\n",
       "Actual                                      \n",
       "0           99  10    4   26   28    0   167\n",
       "1            5  44   12   51   52    3   167\n",
       "2            9   2  124   26    4    1   166\n",
       "3            6  10   19   88   42    2   167\n",
       "4            5  29   11   42   79    1   167\n",
       "5            0   0    7    1    1  158   167\n",
       "All        124  95  177  234  206  165  1001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_predicted)\n",
    "pd.crosstab(y_true, y_predicted, rownames = ['Actual'], colnames =['Predicted'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea54abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.DataFrame(y_true)\n",
    "pred = pd.DataFrame(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2743f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rename(columns={0:'pred_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1940a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.DataFrame(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84366f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_eval = pd.concat([text,actual,pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddd26356",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_label = {0:'extract',1:'inline', 2:'move', 3:'pull-up', 4:'push-down', 5:'rename'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c65a53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_eval['pred_label'] = bert_eval.pred_label.map(num_to_label)\n",
    "bert_eval['label'] = bert_eval.label.map(num_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82b51ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_eval.to_csv('bert_validation_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0520d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('bert_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e294b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
